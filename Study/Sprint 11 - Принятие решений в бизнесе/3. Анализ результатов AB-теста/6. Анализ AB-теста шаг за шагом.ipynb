{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.\n",
    "Изучите устройство таблицы data: выведите первые 5 строк таблицы. По аналогии с кодом в уроке создайте переменные\n",
    "ordersByUsersA и ordersByUsersB со столбцами ['userId', 'orders'], где для пользователей, совершивших хотя бы 1 заказ, будет указано число заказов.\n",
    "Объявите переменные sampleA и sampleB, в которых пользователям с заказами будет соответствовать число заказов пользователя. А пользователям без заказов — нули. Возьмите код из урока в качестве примера.\n",
    "Посчитайте статистическую значимость различия конверсии по результатам двух недель теста. Примените тест Манна-Уитни.\n",
    "Выведите p-value для сравнения конверсии между группами. Округлите p-value до 5 знаков после запятой.\n",
    "Вычислите и выведите относительное различие в конверсии между группами. Округлите до 3 знаков после запятой.\n",
    "\n",
    "Подсказка\n",
    "Изучите решение в теории урока. Найдите относительное различие конверсии группы B так:\n",
    "print(\"{0:.3f}\".format((data['ordersPerDateB'].sum()/data['visitorsPerDateB'].sum())/(data['ordersPerDateA'].sum()/data['visitorsPerDateA'].sum())-1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "visitors = pd.read_csv(filepath_or_buffer='datasets/data_for_tasks_3_visitors.csv')\n",
    "visitors['date'] = visitors['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "orders = pd.read_csv(filepath_or_buffer='datasets/data_for_tasks_3.csv')\n",
    "orders['date'] = orders['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "visitorsADaily = visitors[visitors['group'] == 'A'][['date', 'visitors']]\n",
    "visitorsADaily.columns = ['date', 'visitorsPerDateA']\n",
    "\n",
    "visitorsACummulative = visitorsADaily.apply(\n",
    "    lambda x: visitorsADaily[visitorsADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsACummulative.columns = ['date', 'visitorsCummulativeA']\n",
    "\n",
    "visitorsBDaily = visitors[visitors['group'] == 'B'][['date', 'visitors']]\n",
    "visitorsBDaily.columns = ['date', 'visitorsPerDateB']\n",
    "\n",
    "visitorsBCummulative = visitorsBDaily.apply(\n",
    "    lambda x: visitorsBDaily[visitorsBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsBCummulative.columns = ['date', 'visitorsCummulativeB']\n",
    "\n",
    "ordersADaily = (\n",
    "    orders[orders['group'] == 'A'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersADaily.columns = ['date', 'ordersPerDateA', 'revenuePerDateA']\n",
    "\n",
    "ordersACummulative = ordersADaily.apply(\n",
    "    lambda x: ordersADaily[ordersADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateA': 'sum', 'revenuePerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersACummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeA',\n",
    "    'revenueCummulativeA',\n",
    "]\n",
    "\n",
    "ordersBDaily = (\n",
    "    orders[orders['group'] == 'B'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersBDaily.columns = ['date', 'ordersPerDateB', 'revenuePerDateB']\n",
    "\n",
    "ordersBCummulative = ordersBDaily.apply(\n",
    "    lambda x: ordersBDaily[ordersBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateB': 'sum', 'revenuePerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersBCummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeB',\n",
    "    'revenueCummulativeB',\n",
    "]\n",
    "\n",
    "data = (\n",
    "    ordersADaily.merge(\n",
    "        ordersBDaily, left_on='date', right_on='date', how='left'\n",
    "    )\n",
    "    .merge(ordersACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(ordersBCummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsADaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBDaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBCummulative, left_on='date', right_on='date', how='left')\n",
    ")\n",
    "\n",
    "print(data.head(5))\n",
    "\n",
    "ordersByUsersA = (\n",
    "    orders[orders['group'] == 'A']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersA.columns = ['userId', 'orders']\n",
    "\n",
    "ordersByUsersB = (\n",
    "    orders[orders['group'] == 'B']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersB.columns = ['userId', 'orders']\n",
    "\n",
    "sampleA = pd.concat([ordersByUsersA['orders'],pd.Series(0, index=np.arange(data['visitorsPerDateA'].sum() - len(ordersByUsersA['orders'])), name='orders')],axis=0)\n",
    "\n",
    "sampleB = pd.concat([ordersByUsersB['orders'],pd.Series(0, index=np.arange(data['visitorsPerDateB'].sum() - len(ordersByUsersB['orders'])), name='orders')],axis=0)\n",
    "\n",
    "print(\"{0:.3f}\".format(stats.mannwhitneyu(sampleA, sampleB)[1]))\n",
    "\n",
    "print(\"{0:.3f}\".format(sampleB.mean() / sampleA.mean() - 1))\n",
    "\n",
    "print(\"{0:.3f}\".format((data['ordersPerDateB'].sum()/data['visitorsPerDateB'].sum())/(data['ordersPerDateA'].sum()/data['visitorsPerDateA'].sum())-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.\n",
    "Посчитайте статистическую значимость различия средних чеков между группами.\n",
    "Выведите p-value для сравнения средних чеков между группами. Округлите p-value до трёх знаков после запятой.\n",
    "Выведите относительный прирост среднего чека группы B, округлив до трёх знаков после запятой.\n",
    "\n",
    "Подсказка\n",
    "Напишите код по аналогии с примером в теории урока."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "visitors = pd.read_csv('datasets/data_for_tasks_3_visitors.csv')\n",
    "visitors['date'] = visitors['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "orders = pd.read_csv('datasets/data_for_tasks_3.csv')\n",
    "orders['date'] = orders['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "visitorsADaily = visitors[visitors['group'] == 'A'][['date', 'visitors']]\n",
    "visitorsADaily.columns = ['date', 'visitorsPerDateA']\n",
    "\n",
    "visitorsACummulative = visitorsADaily.apply(\n",
    "    lambda x: visitorsADaily[visitorsADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsACummulative.columns = ['date', 'visitorsCummulativeA']\n",
    "\n",
    "visitorsBDaily = visitors[visitors['group'] == 'B'][['date', 'visitors']]\n",
    "visitorsBDaily.columns = ['date', 'visitorsPerDateB']\n",
    "\n",
    "visitorsBCummulative = visitorsBDaily.apply(\n",
    "    lambda x: visitorsBDaily[visitorsBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsBCummulative.columns = ['date', 'visitorsCummulativeB']\n",
    "\n",
    "ordersADaily = (\n",
    "    orders[orders['group'] == 'A'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersADaily.columns = ['date', 'ordersPerDateA', 'revenuePerDateA']\n",
    "\n",
    "ordersACummulative = ordersADaily.apply(\n",
    "    lambda x: ordersADaily[ordersADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateA': 'sum', 'revenuePerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersACummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeA',\n",
    "    'revenueCummulativeA',\n",
    "]\n",
    "\n",
    "ordersBDaily = (\n",
    "    orders[orders['group'] == 'B'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersBDaily.columns = ['date', 'ordersPerDateB', 'revenuePerDateB']\n",
    "\n",
    "ordersBCummulative = ordersBDaily.apply(\n",
    "    lambda x: ordersBDaily[ordersBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateB': 'sum', 'revenuePerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersBCummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeB',\n",
    "    'revenueCummulativeB',\n",
    "]\n",
    "\n",
    "data = (\n",
    "    ordersADaily.merge(\n",
    "        ordersBDaily, left_on='date', right_on='date', how='left'\n",
    "    )\n",
    "    .merge(ordersACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(ordersBCummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsADaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBDaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBCummulative, left_on='date', right_on='date', how='left')\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"{0:.3f}\".format(\n",
    "        stats.mannwhitneyu(\n",
    "            orders[orders['group'] == 'A']['revenue'],\n",
    "            orders[orders['group'] == 'B']['revenue'],\n",
    "        )[1]\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"{0:.3f}\".format(\n",
    "        orders[orders['group'] == 'B']['revenue'].mean()\n",
    "        / orders[orders['group'] == 'A']['revenue'].mean()\n",
    "        - 1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.\n",
    "Приступаем к подготовке очищенных от аномалий данных.\n",
    "Напомним, что 95-й и 99-й перцентили средних чеков равны 7 740 и 43 570 рублям. А 95-й и 99-й перцентили числа заказов на одного пользователя равны 2 и 3 заказам на пользователя.\n",
    "Примите за аномальных пользователей тех, кто совершил 3 заказа и более, или совершил заказ на сумму свыше 10 000 рублей. Так вы уберёте 1% пользователей с наибольшим числом заказов и от 1% до 5% заказов с наибольшей стоимостью.\n",
    "Удалять нужно именно пользователей — сначала определить аномальные заказы. Затем пользователей, совершивших их, и добавить их в список аномальных.\n",
    "Сделайте срезы пользователей с числом заказов больше 2 — usersWithManyOrders и пользователей, совершивших заказы дороже 10 000 — usersWithExpensiveOrders. Объедините их в таблице abnormalUsers, удалите дубликаты, отсортируйте по возрастанию.\n",
    "Выведите первые 5 строк переменной abnormalUsers.\n",
    "\n",
    "Подсказка\n",
    "Изучите код в теоретической части урока.\n",
    "Отфильтруйте значения так: ordersByUsersA[ordersByUsersA['orders'] > 2]['userId']\n",
    "Объедините таблицы функцией concat(). Удалите дубликаты методом drop_duplicates(). Отсортируйте данные методом sort_values() по возрастанию."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2981    4.246030e+15\n",
      "3742    1.424692e+17\n",
      "16      2.374281e+17\n",
      "1156    3.539876e+17\n",
      "30      4.867316e+17\n",
      "Name: userId, dtype: float64\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "visitors = pd.read_csv('datasets/data_for_tasks_3_visitors.csv')\n",
    "visitors['date'] = visitors['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "orders = pd.read_csv('datasets/data_for_tasks_3.csv')\n",
    "orders['date'] = orders['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "ordersByUsersA = (\n",
    "    orders[orders['group'] == 'A']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersA.columns = ['userId', 'orders']\n",
    "\n",
    "ordersByUsersB = (\n",
    "    orders[orders['group'] == 'B']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersB.columns = ['userId', 'orders']\n",
    "\n",
    "usersWithManyOrders = pd.concat(\n",
    "    [\n",
    "        ordersByUsersA[ordersByUsersA['orders'] > 2]['userId'],\n",
    "        ordersByUsersB[ordersByUsersB['orders'] > 2]['userId'],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "usersWithExpensiveOrders = orders[orders['revenue'] > 10000]['userId']\n",
    "abnormalUsers = (\n",
    "    pd.concat([usersWithManyOrders, usersWithExpensiveOrders], axis=0)\n",
    "    .drop_duplicates()\n",
    "    .sort_values()\n",
    ")\n",
    "print(abnormalUsers.head(5))\n",
    "print(abnormalUsers.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.\n",
    "Посчитайте статистическую значимость различия конверсии после удаления аномальных пользователей.\n",
    "Создайте переменные sampleAFiltered и sampleBFiltered, в которых сохраните очищенные данные о заказах — не включая аномальных пользователей.\n",
    "Выведите p-value для сравнения конверсии между очищенными группами. Округлите p-value до пяти знаков после запятой. Выведите относительный прирост конверсии очищенной группы B, округлив до трёх знаков после запятой.\n",
    "\n",
    "Подсказка\n",
    "Пример создания очищенной выборки для группы A:\n",
    "sampleAFiltered = pd.concat(\n",
    "    [\n",
    "        ordersByUsersA[\n",
    "            np.logical_not(ordersByUsersA['userId'].isin(abnormalUsers))\n",
    "        ]['orders'],\n",
    "        pd.Series(\n",
    "            0,\n",
    "            index=np.arange(\n",
    "                data['visitorsPerDateA'].sum() - len(ordersByUsersA['orders'])\n",
    "            ),\n",
    "            name='orders',\n",
    "        ),\n",
    "    ],\n",
    "    axis=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00046\n",
      "0.186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "visitors = pd.read_csv('datasets/data_for_tasks_3_visitors.csv')\n",
    "visitors['date'] = visitors['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "orders = pd.read_csv('datasets/data_for_tasks_3.csv')\n",
    "orders['date'] = orders['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "visitorsADaily = visitors[visitors['group'] == 'A'][['date', 'visitors']]\n",
    "visitorsADaily.columns = ['date', 'visitorsPerDateA']\n",
    "\n",
    "visitorsACummulative = visitorsADaily.apply(\n",
    "    lambda x: visitorsADaily[visitorsADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsACummulative.columns = ['date', 'visitorsCummulativeA']\n",
    "\n",
    "visitorsBDaily = visitors[visitors['group'] == 'B'][['date', 'visitors']]\n",
    "visitorsBDaily.columns = ['date', 'visitorsPerDateB']\n",
    "\n",
    "visitorsBCummulative = visitorsBDaily.apply(\n",
    "    lambda x: visitorsBDaily[visitorsBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsBCummulative.columns = ['date', 'visitorsCummulativeB']\n",
    "\n",
    "ordersADaily = (\n",
    "    orders[orders['group'] == 'A'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersADaily.columns = ['date', 'ordersPerDateA', 'revenuePerDateA']\n",
    "\n",
    "ordersACummulative = ordersADaily.apply(\n",
    "    lambda x: ordersADaily[ordersADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateA': 'sum', 'revenuePerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersACummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeA',\n",
    "    'revenueCummulativeA',\n",
    "]\n",
    "\n",
    "ordersBDaily = (\n",
    "    orders[orders['group'] == 'B'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersBDaily.columns = ['date', 'ordersPerDateB', 'revenuePerDateB']\n",
    "\n",
    "ordersBCummulative = ordersBDaily.apply(\n",
    "    lambda x: ordersBDaily[ordersBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateB': 'sum', 'revenuePerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersBCummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeB',\n",
    "    'revenueCummulativeB',\n",
    "]\n",
    "\n",
    "data = (\n",
    "    ordersADaily.merge(\n",
    "        ordersBDaily, left_on='date', right_on='date', how='left'\n",
    "    )\n",
    "    .merge(ordersACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(ordersBCummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsADaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBDaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBCummulative, left_on='date', right_on='date', how='left')\n",
    ")\n",
    "\n",
    "ordersByUsersA = (\n",
    "    orders[orders['group'] == 'A']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersA.columns = ['userId', 'orders']\n",
    "\n",
    "ordersByUsersB = (\n",
    "    orders[orders['group'] == 'B']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersB.columns = ['userId', 'orders']\n",
    "\n",
    "\n",
    "usersWithManyOrders = pd.concat(\n",
    "    [\n",
    "        ordersByUsersA[ordersByUsersA['orders'] > 2]['userId'],\n",
    "        ordersByUsersB[ordersByUsersB['orders'] > 2]['userId'],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "usersWithExpensiveOrders = orders[orders['revenue'] > 10000]['userId']\n",
    "abnormalUsers = (\n",
    "    pd.concat([usersWithManyOrders, usersWithExpensiveOrders], axis=0)\n",
    "    .drop_duplicates()\n",
    "    .sort_values()\n",
    ")\n",
    "sampleAFiltered = pd.concat(\n",
    "    [\n",
    "        ordersByUsersA[\n",
    "            np.logical_not(ordersByUsersA['userId'].isin(abnormalUsers))\n",
    "        ]['orders'],\n",
    "        pd.Series(\n",
    "            0,\n",
    "            index=np.arange(\n",
    "                data['visitorsPerDateA'].sum() - len(ordersByUsersA['orders'])\n",
    "            ),\n",
    "            name='orders',\n",
    "        ),\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "sampleBFiltered = pd.concat(\n",
    "    [\n",
    "        ordersByUsersB[\n",
    "            np.logical_not(ordersByUsersB['userId'].isin(abnormalUsers))\n",
    "        ]['orders'],\n",
    "        pd.Series(\n",
    "            0,\n",
    "            index=np.arange(\n",
    "                data['visitorsPerDateB'].sum() - len(ordersByUsersB['orders'])\n",
    "            ),\n",
    "            name='orders',\n",
    "        ),\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "print('{0:.5f}'.format(stats.mannwhitneyu(sampleAFiltered, sampleBFiltered)[1]))\n",
    "print('{0:.3f}'.format(sampleBFiltered.mean()/sampleAFiltered.mean()-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.\n",
    "Посчитайте статистическую значимость различия средних чеков после удаления аномальных пользователей.\n",
    "Выведите p-value для сравнения средних чеков между очищенными группами. Округлите p-value до трёх знаков после запятой. Выведите относительный прирост среднего чека очищенной группы B, округлив до трёх знаков после запятой.\n",
    "\n",
    "Подсказка\n",
    "Изучите код из теории урока."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029\n",
      "0.007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "visitors = pd.read_csv('datasets/data_for_tasks_3_visitors.csv')\n",
    "visitors['date'] = visitors['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "orders = pd.read_csv('datasets/data_for_tasks_3.csv')\n",
    "orders['date'] = orders['date'].map(\n",
    "    lambda x: dt.datetime.strptime(x, '%d/%m/%Y')\n",
    ")\n",
    "\n",
    "visitorsADaily = visitors[visitors['group'] == 'A'][['date', 'visitors']]\n",
    "visitorsADaily.columns = ['date', 'visitorsPerDateA']\n",
    "\n",
    "visitorsACummulative = visitorsADaily.apply(\n",
    "    lambda x: visitorsADaily[visitorsADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsACummulative.columns = ['date', 'visitorsCummulativeA']\n",
    "\n",
    "visitorsBDaily = visitors[visitors['group'] == 'B'][['date', 'visitors']]\n",
    "visitorsBDaily.columns = ['date', 'visitorsPerDateB']\n",
    "\n",
    "visitorsBCummulative = visitorsBDaily.apply(\n",
    "    lambda x: visitorsBDaily[visitorsBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'visitorsPerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "visitorsBCummulative.columns = ['date', 'visitorsCummulativeB']\n",
    "\n",
    "ordersADaily = (\n",
    "    orders[orders['group'] == 'A'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersADaily.columns = ['date', 'ordersPerDateA', 'revenuePerDateA']\n",
    "\n",
    "ordersACummulative = ordersADaily.apply(\n",
    "    lambda x: ordersADaily[ordersADaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateA': 'sum', 'revenuePerDateA': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersACummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeA',\n",
    "    'revenueCummulativeA',\n",
    "]\n",
    "\n",
    "ordersBDaily = (\n",
    "    orders[orders['group'] == 'B'][['date', 'orderId', 'userId', 'revenue']]\n",
    "    .groupby('date', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique, 'revenue': 'sum'})\n",
    ")\n",
    "ordersBDaily.columns = ['date', 'ordersPerDateB', 'revenuePerDateB']\n",
    "\n",
    "ordersBCummulative = ordersBDaily.apply(\n",
    "    lambda x: ordersBDaily[ordersBDaily['date'] <= x['date']].agg(\n",
    "        {'date': 'max', 'ordersPerDateB': 'sum', 'revenuePerDateB': 'sum'}\n",
    "    ),\n",
    "    axis=1,\n",
    ").sort_values(by=['date'])\n",
    "ordersBCummulative.columns = [\n",
    "    'date',\n",
    "    'ordersCummulativeB',\n",
    "    'revenueCummulativeB',\n",
    "]\n",
    "\n",
    "data = (\n",
    "    ordersADaily.merge(\n",
    "        ordersBDaily, left_on='date', right_on='date', how='left'\n",
    "    )\n",
    "    .merge(ordersACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(ordersBCummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsADaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBDaily, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsACummulative, left_on='date', right_on='date', how='left')\n",
    "    .merge(visitorsBCummulative, left_on='date', right_on='date', how='left')\n",
    ")\n",
    "\n",
    "ordersByUsersA = (\n",
    "    orders[orders['group'] == 'A']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersA.columns = ['userId', 'orders']\n",
    "\n",
    "ordersByUsersB = (\n",
    "    orders[orders['group'] == 'B']\n",
    "    .groupby('userId', as_index=False)\n",
    "    .agg({'orderId': pd.Series.nunique})\n",
    ")\n",
    "ordersByUsersB.columns = ['userId', 'orders']\n",
    "\n",
    "usersWithManyOrders = pd.concat(\n",
    "    [\n",
    "        ordersByUsersA[ordersByUsersA['orders'] > 2]['userId'],\n",
    "        ordersByUsersB[ordersByUsersB['orders'] > 2]['userId'],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "usersWithExpensiveOrders = orders[orders['revenue'] > 10000]['userId']\n",
    "abnormalUsers = (\n",
    "    pd.concat([usersWithManyOrders, usersWithExpensiveOrders], axis=0)\n",
    "    .drop_duplicates()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "print(\n",
    "    '{0:.3f}'.format(\n",
    "        stats.mannwhitneyu(\n",
    "            orders[\n",
    "                np.logical_and(\n",
    "                    orders['group'] == 'A',\n",
    "                    np.logical_not(orders['userId'].isin(abnormalUsers)),\n",
    "                )\n",
    "            ]['revenue'],\n",
    "            orders[\n",
    "                np.logical_and(\n",
    "                    orders['group'] == 'B',\n",
    "                    np.logical_not(orders['userId'].isin(abnormalUsers)),\n",
    "                )\n",
    "            ]['revenue'],\n",
    "        )[1]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"{0:.3f}\".format(\n",
    "        orders[\n",
    "            np.logical_and(\n",
    "                orders['group'] == 'B',\n",
    "                np.logical_not(orders['userId'].isin(abnormalUsers)),\n",
    "            )\n",
    "        ]['revenue'].mean()\n",
    "        / orders[\n",
    "            np.logical_and(\n",
    "                orders['group'] == 'A',\n",
    "                np.logical_not(orders['userId'].isin(abnormalUsers)),\n",
    "            )\n",
    "        ]['revenue'].mean()\n",
    "        - 1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}